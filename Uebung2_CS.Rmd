---
output:
  pdf_document: default
  html_document: default
header-includes: 
    - \usepackage{amsthm}
    - \usepackage{xcolor}
documentclass: article
<!---output: beamer_presentation--->
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
                      collapse=TRUE,     # collapse by default
                      echo=TRUE,         # echo code by default
                      comment = "#>",    # change comment character
                      fig.width = 10,     # set figure width
                      out.width = "100%", # set width of displayed images
                      warning=TRUE,      # show R warnings
                      message=FALSE)     # show R messages

packageTest<- function(x)  {
    if (!require(x,character.only = TRUE))  {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
}

options(warn=-1)
```


<!--- Solution Region --->
<style>
#solution {
  background-color: #8FBC8F;
  border-style: solid;
  border-color: blue;
  margin-left: 20px;
  margin-bottom: 15px;
  padding: 5px;
}
</style>



<!---**Sommersemester 2019 |Studiengang Data Science | Hochschule Darmstadt **--->




\theoremstyle{break}
\newtheorem{auf}{Aufgabe}

\newcommand{\R}{{\sffamily R} }

\begin{centering}
%\vspace{-2 cm}
\Huge
{\bf Uebung 1}\\
\Large
Computational Statistics\\
\normalsize
Sommersemester 2019\\
April 15, 2019\\
J. Groos (FBMN, h\_da)\\
\end{centering}


\hrulefill

**Name:**

\hrulefill


## A 1

```{r}
load(file = "Donald.RData") # importiere Datensatz

## Vergleich der Variablenverteilung zwischen Trainings- und Testdatensatz/Lineare Regression (Drei Mal)
for (i in 1:3){ 
smp_size <- 100
train_ind <- sample(seq_len(nrow(Donald_1)), size = smp_size)

train <- Donald_1[train_ind, ]
test <- Donald_1[-train_ind, ]
print(i)
cat("train: \n\n")
print(summary(train))
cat("\n")
cat("test: \n\n")
print(summary(test))
linreg <- lm(Trump ~ Alter + Geschlecht + Minderheit + Fremdenfeindlich + IQ, data = train)
pred <- predict.lm(linreg, test)
cat("\n")
cat("MSE: \n")
print(mean((test$Trump - pred) ^ 2))
cat("_______________________________ \n\n")
}

```
Durch die zuf�llige Aufteilung der Datenpunkte in zwei disjunkte Datens�tze (train, test) entstehen Diskrepanzen zwischen den Verteilungen der Variablen. Diese Schwankungen wirken sich dann auch auf die Modellg�te aus. 
Wir wissen aus der vergangenen �bung, dass das Merkmal "Fremdenfeinlich" der "st�rkste" Prediktor der abh�ngigen Variablen ist. Vergleichen wir die Verteilung dieses Merkmals zwischen Train- und Testdatensatz in 1 mit dem aus 3, f�llt auf, dass die Diskrepanzen zwischen train und test in 3 eindeutig st�rker ausfallen, als in 1. Dies spiegelt sich im jeweiligen MSE wieder: Das Modell, welches mit den Daten aus 1 trainiert und getestet wurde, weist einen deutlich niedrigeren MSE auf, als das Modell aus 3.

## A 2
### a)
```{r}
mse <- c()
for (i in 1:nrow(Donald_1)){
  lou <- lm(Trump ~ Alter + Geschlecht + Minderheit + Fremdenfeindlich + IQ, data = Donald_1[-i,])
  pred <- predict.lm(lou, Donald_1[i,])
  mse[i] <- mean((Donald_1[i,]$Trump - pred) ^ 2)
}

mse <- sum(mse)/nrow(Donald_1)
mse
```
Hier könnte ihre Interpretation stehen:

### b)
```{r}
packageTest('boot')

model <- glm(Trump ~ Alter + Geschlecht + Minderheit + Fremdenfeindlich + IQ, data = Donald_1)

cv_model <- cv.glm(Donald_1, model, K = nrow(Donald_1))

mse1 <- cv_model$delta
mse1
```
Die Implementierung des "Leave-one-out cross-validation"-Verfahrens durch cv.glm gibt zwei Modellgütemetriken zurück. Der erste Wert ist der durschnittliche MSE über die Zeilen. Dieser ist identisch mit dem Wert aus a). Man kann vermuten, dass die Implementierung des "Leave-one-out cross-validation"-Verfahrens durch cv.glm identisch mit unserer manuellen Implementierung aus a) ist. Der zweite Wert ist laut Dokumentation ein Bias-korrigierter MSE. 

## A 3
```{r}
mse2 <- c()
for (k in c(5,10)){
  for (i in 1:10){
    mse2 <- c(mse2, cv.glm(Donald_1, model, K = k)$delta[1])
  }
}

print('MSE 5-Fold Cross-Validation:')
mse2[1:5]
cat('\n')
print('MSE 10-Fold Cross-Validation:')
mse2[6:10]

plot(mse2[1:5], type='ol',ylab='MSE', main='5-Fold Cross-Validation')
plot(mse2[6:10], type='ol',ylab='MSE', main='10-Fold Cross-Validation')
```
Hier könnte ihre Interpretation stehen:
