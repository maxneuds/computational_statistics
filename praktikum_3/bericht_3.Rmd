
---
output:
  pdf_document: default
  html_document: default
header-includes: 
    - \usepackage{amsthm}
    - \usepackage{xcolor}
documentclass: article
<!---output: beamer_presentation--->
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
                      collapse=TRUE,     # collapse by default
                      echo=TRUE,         # echo code by default
                      comment = "#>",    # change comment character
                      fig.width = 10,     # set figure width
                      out.width = "100%", # set width of displayed images
                      warning=TRUE,      # show R warnings
                      message=FALSE)     # show R messages
packageTest<- function(x)  {
    if (!require(x,character.only = TRUE))  {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
}
options(warn=-1)
```


<!--- Solution Region --->
<style>
#solution {
  background-color: #8FBC8F;
  border-style: solid;
  border-color: blue;
  margin-left: 20px;
  margin-bottom: 15px;
  padding: 5px;
}
</style>



<!---**Sommersemester 2019 |Studiengang Data Science | Hochschule Darmstadt **--->




\theoremstyle{break}
\newtheorem{auf}{Aufgabe}

\newcommand{\R}{{\sffamily R} }

\begin{centering}
%\vspace{-2 cm}
\Huge
{\bf Übung 3}\\
\Large
Computational Statistics\\
\normalsize
Sommersemester 2019\\
April 15, 2019\\
J. Groos (FBMN, h\_da)\\
\end{centering}


\hrulefill

**Name:**

\hrulefill


## A 1 
###a)

```{r}
means50 = matrix(NA, nrow = 50, ncol = 1)
for (i in 1:50){
  summe = runif(500,0,1)
  means50[i,] = mean(summe)
}
means1000 = matrix(NA, nrow = 1000, ncol = 1)
for (i in 1:1000){
  summe = runif(500,0,1)
  means1000[i,] = mean(summe)
}
head(means1000)
```

###b) & c)
```{r}
packageTest('boot')
bootdata <- runif(500,0,1)
bootfunc <- function(data,i) {
  d <- data[i]
  return(mean(d))
}
boot50 <- boot(bootdata, bootfunc, R = 50)
boot50 <- boot50$t
boot1000 <- boot(bootdata, bootfunc, R = 1000)
boot1000 <- boot1000$t
hist(boot50)
hist(boot1000)
hist(means50)
hist(means1000)
boxplot(boot50, main='Boxplot of Bootstrap (R = 50)')
boxplot(boot1000, main='Boxplot of Bootstrap (R = 1000)')
boxplot(means50, main='Boxplot of n=50')
boxplot(means1000, main='Boxplot of n=1000')
par(mfrow=c(2,2))
qqnorm(boot50, main='QQPlot Bootstrap (R = 50)')
qqline(boot50)
qqnorm(boot1000, main='QQPlot Bootstrap (R = 1000)')
qqline(boot1000)
qqnorm(means50, main='QQPlot n=50')
qqline(means50)
qqnorm(means1000, main='QQPlot n=1000')
qqline(means1000)
shapiro.test(means50)
shapiro.test(means1000)
shapiro.test(boot50)
shapiro.test(boot1000)
```
Laut Shapiro-Wilks-Test kann für keine der vier Stichproben die Nullhypothese (Stichprobe ist normalverteilt) verworfen werden, auch wenn die Histogramme von boot50 und means50 nicht nach Normalverteilung aussehen.


### d)
```{r}
packageTest('car')

levene50 <- c(means50,boot50)

levene1000 <- c(means1000,boot1000)

levgroup50 <- as.factor(c(rep(1, length(means50)), rep(2, length(boot50))))


levgroup1000 <- as.factor(c(rep(1, length(means1000)), rep(2, length(boot1000))))
leveneTest(levene50, levgroup50)

leveneTest(levene1000, levgroup1000)

t.test(means50, boot50, var.equal = TRUE)

t.test(means1000, boot1000, var.equal = TRUE)
```
Um t-Tests durchführen zu können, müssen die Gruppen erst auf Varianzhomogenität geprüft werden. Diese wird mit dem Levene-Test geprüft. Laut diesem ist die Varianzhomogenität sowohl für $\operatorname{Means}_{sim50}$ und $\operatorname{Means}_{boot50}$ und $\operatorname{Means}_{sim1000}$ und $\operatorname{Means}_{boot1000}$ gegeben. 

Der t-Test zur Überprüfung der Mittelwerte von $\operatorname{Means}_{sim50}$ und $\operatorname{Means}_{boot50}$ lieferte ein insignifikantes Ergebnis. Aus diesem Grund kann die Nullhypothese ("Differenz der Mittelwerte gleich 0.") nicht verworfen werden. 

Für die Mittelwerte von $\operatorname{Means}_{sim1000}$ und $\operatorname{Means}_{boot1000}$ kann die Nullhypothese mit einem Siginifkanzniveau von 95% verworfen werden.

## Aufgabe 2
### a)
```{r}
load("Donald.RData")
vergleich <- lm(data = Donald_1, Trump ~ Geschlecht + Alter + Minderheit + Fremdenfeindlich + IQ)
theta <- function(formula, data, indices){
  d <- data[indices,]
  fit <- lm(formula, data = d)
  return(coef(fit))
}

coef_names <- names(vergleich$coefficients)

boot50_1 <- boot(data=Donald_1, statistic=theta, R=50, formula=Trump~.)
par(mfrow=c(1,2))
for (i in 1:6){
hist(boot50_1$t[,i], main=paste("boot_50: Coefficient", coef_names[i]), xlab = coef_names[i])
qqnorm(boot50_1$t[,i], main = NULL)
qqline(boot50_1$t[,i])
print(t.test(boot50_1$t[,i], mu=vergleich$coefficients[i]))
}
boot100_1 <- boot(data=Donald_1, statistic=theta, R=100, formula=Trump~.)
par(mfrow=c(1,2))
for (i in 1:6){
hist(boot100_1$t[,i], main=paste("boot_100: Coefficient", coef_names[i]), xlab = coef_names[i])
qqnorm(boot100_1$t[,i], main = NULL)
qqline(boot100_1$t[,i])
print(t.test(boot100_1$t[,i], mu=vergleich$coefficients[i]))
}
boot1000_1 <- boot(data=Donald_1, statistic=theta, R=1000, formula=Trump~.)
par(mfrow=c(1,2))
for (i in 1:6){
hist(boot1000_1$t[,i], main=paste("boot_1000: Coefficient", coef_names[i]), xlab = coef_names[i])
qqnorm(boot1000_1$t[,i], main = NULL)
qqline(boot1000_1$t[,i])
print(t.test(boot1000_1$t[,i], mu=vergleich$coefficients[i]))
}
boot10000_1 <- boot(data=Donald_1, statistic=theta, R=10000, formula=Trump~.)
par(mfrow=c(1,2))
for (i in 1:6){
hist(boot10000_1$t[,i], main=paste("boot_10000: Coefficient", coef_names[i]), xlab = coef_names[i])
qqnorm(boot10000_1$t[,i], main = NULL)
qqline(boot10000_1$t[,i])
print(t.test(boot10000_1$t[,i], mu=vergleich$coefficients[i]))
}
```
Hier untersuchen wir, ob wir durch das Bootstrappingverfahren auf das gleiche Ergebnis kommen wie die lineare Regression. Außerdem vergleichen wir die Verteilungen der Parameterschätzer für verschiedene Replikationsgrößen.
Zu den Verteilungen lässt sich, wie bei Aufgabe 1, sagen, dass sich die Verteilungen mit mehr Replikationen immer mehr an die Normalverteilung annähern. Dies lässt sich an den Histogrammen, sowie den qqnorm-Plots ablesen. 
Die t-Tests sind tendenziell insignifikant (p-Wert > 0.05), die Nullhypothesen können deshalb nicht verworfen werden. Es gibt vereinzelt Ausnahmen (Beispiel: Bei boot_100 Geschlecht). 

### b)
```{r}
Konfi50 <- matrix(NA,6,2)
rownames(Konfi50) <- c("Intercept","Geschlecht","Alter","Minderheit","Fremdenfeindlich","IQ")
colnames(Konfi50) <- c("2,5%","97,5%")
for(i in 1:6)
{
    Konfi50[i,1] <- boot.ci(boot50_1, type="basic", index = i)$basic[4]
    Konfi50[i,2] <- boot.ci(boot50_1, type="basic", index = i)$basic[5]
}
Konfi100 <- matrix(NA,6,2)
rownames(Konfi100) <- c("Intercept","Geschlecht","Alter","Minderheit","Fremdenfeindlich","IQ")
colnames(Konfi100) <- c("2,5%","97,5%")
for(i in 1:6)
{
    Konfi100[i,1] <- boot.ci(boot100_1, type="basic", index = i)$basic[4]
    Konfi100[i,2] <- boot.ci(boot100_1, type="basic", index = i)$basic[5]
}
Konfi1000 <- matrix(NA,6,2)
rownames(Konfi1000) <- c("Intercept","Geschlecht","Alter","Minderheit","Fremdenfeindlich","IQ")
colnames(Konfi1000) <- c("2,5%","97,5%")
for(i in 1:6)
{
    Konfi1000[i,1] <- boot.ci(boot1000_1, type="basic", index = i)$basic[4]
    Konfi1000[i,2] <- boot.ci(boot1000_1, type="basic", index = i)$basic[5]
}
Konfi10000 <- matrix(NA,6,2)
rownames(Konfi10000) <- c("Intercept","Geschlecht","Alter","Minderheit","Fremdenfeindlich","IQ")
colnames(Konfi10000) <- c("2,5%","97,5%")
for(i in 1:6)
{
    Konfi10000[i,1] <- boot.ci(boot10000_1, type="basic", index = i)$basic[4]
    Konfi10000[i,2] <- boot.ci(boot10000_1, type="basic", index = i)$basic[5]
}
Konfi50
Konfi100
Konfi1000
Konfi10000
```
### c)
```{r}
confint(vergleich,level=0.95)
Konfi50
Konfi100
Konfi1000
Konfi10000
```
Die Unterschiede der Konfidenzintervalle durch Bootstrapping mit dem Konfidenzintervall der linearen Regression sind verschwindend gering, deshalb ist eine Empfehlung schwierig. Wir würden uns für ein bootstrapping mit Replikationsgröße 10000 entscheiden, da hier die Unterschiede wohl am geringsten sind.

Interessanterweise ist bei boot_100 das Konfidenzintervall für den Parameterschätzer der Kovariaten "Geschlecht" am unterschiedlichsten zum Konfidenzinterall der linearen Regression. Im Gegensatz zu den anderen Replikationsgrößen ist dieses Intervall nach unten verschoben. Dies schneidet sich mit der in Aufgabe 2a) aufgetretetenen Anomalie.

### d)
```{r}
Konfi1000perc <- matrix(NA,6,2)
rownames(Konfi1000perc) <- c("Intercept","Geschlecht","Alter","Minderheit","Fremdenfeindlich","IQ")
colnames(Konfi1000perc) <- c("2,5%","97,5%")
for(i in 1:6)
{
    Konfi1000perc[i,1] <- boot.ci(boot1000_1, type="perc", index = i)$perc[4]
    Konfi1000perc[i,2] <- boot.ci(boot1000_1, type="perc", index = i)$perc[5]
}
Konfi1000bca <- matrix(NA,6,2)
rownames(Konfi1000bca) <- c("Intercept","Geschlecht","Alter","Minderheit","Fremdenfeindlich","IQ")
colnames(Konfi1000bca) <- c("2,5%","97,5%")
for(i in 1:6)
{
    Konfi1000bca[i,1] <- boot.ci(boot1000_1, type="bca", index = i)$bca[4]
    Konfi1000bca[i,2] <- boot.ci(boot1000_1, type="bca", index = i)$bca[5]
}
Konfi1000
Konfi1000perc
Konfi1000bca
```

Wir sehen hier keine großen Unterschiede in den Konfidenzintervallen. 